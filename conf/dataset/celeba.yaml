# @package _global_

# data 
Dataset: celeba
data:
  dataset: "superres_4_noise_0.2"
  image_size: 64
  channels: 3
  random_flip: true
y_cond:
  - test_ds[0][1]
  - test_ds[1][1]
  - test_ds[2][1]
  - test_ds[3][1]
  - test_ds[4][1]
  - test_ds[5][1]
  - test_ds[6][1]
  - test_ds[7][1]
  - test_ds[8][1]
  - test_ds[9][1]
x_cond_true:
  - test_ds[0][0]
  - test_ds[1][0]
  - test_ds[2][0]
  - test_ds[3][0]
  - test_ds[4][0]
  - test_ds[5][0]
  - test_ds[6][0]
  - test_ds[7][0]
  - test_ds[8][0]
  - test_ds[9][0]


# transfer
transfer: False
Dataset_transfer: mnist
cond_final: False
cond_final_model:
  MODEL: BasicCond
  mean_scale: 1.
  std_scale: 1.
  adaptive_std: True


adaptive_mean: False
final_adaptive: False
mean_final: torch.zeros([${data.channels}, ${data.image_size}, ${data.image_size}])
var_final: 1*torch.ones([${data.channels}, ${data.image_size}, ${data.image_size}])

# device
device: cuda
num_workers: 8
pin_memory: True

# logging
log_stride: 10
gif_stride: 5000
plot_npar: 10000
test_npar: 100

# training
cache_refresh_stride: 2000
cache_npar: 250
num_cache_batches: 20
use_prev_net: True
ema: True
ema_rate: 0.999
grad_clipping: True
grad_clip: 1.0
batch_size: 128
num_iter: 50000
n_ipf: 20
lr: 0.0001

# diffusion schedule
num_steps: 50
gamma_max: 0.1
gamma_min: 0.00005
gamma_space: linspace
weight_distrib: False
weight_distrib_alpha: 100
fast_sampling: True

